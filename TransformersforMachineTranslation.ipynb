{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c5edd8",
   "metadata": {},
   "source": [
    "__Group Name__ : __Data Dynamo__\n",
    "1. Roy, Abhijith; `abhijithroy.roy@carelon.com`,\n",
    "2. Acharya, Ananth; `ananth.acharya@carelon.com`; \n",
    "3. Kumar, Diwakar; `diwakar.kumar@carelon.com`; \n",
    "4. Gouse, Mohammad; `mohammad.gouse@carelon.com`;\n",
    "5. Peketi, Santhosh; `santhosh.peketi@carelon.com`, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e644967",
   "metadata": {},
   "source": [
    "## Coding Transformer from scratch to perform Machine Translation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33acbd31",
   "metadata": {
    "id": "_GEDUbWFD2ut"
   },
   "source": [
    "__The dataset is a subset of the IWSLT dataset consisting of TEDx Talks that are available in both french and english parallel corpuses__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a72c1c",
   "metadata": {
    "id": "xxnbBPmPixA7"
   },
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84dc491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import  TextVectorization, Embedding, Layer\n",
    "import numpy as np## Importing Dependencies\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import re\n",
    "import time\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac82492",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_datasets.core.logging as _tfds_logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04c74b1",
   "metadata": {
    "id": "i6aPWuOEEVVK"
   },
   "source": [
    "## Loading the train, dev, and test sets of french and english corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df38513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\AL56154\\OneDrive - Elevance Health\\Desktop\\workshop_material\\Total training material\\Transformers_data\\Transformers_data\\train.en\",\n",
    "          mode='r',\n",
    "          encoding='utf-8') as f:\n",
    "    eurotrain_en = f.read()## Loading the train, dev, and test sets of french and english corpora\n",
    "    \n",
    "with open(r\"C:\\Users\\AL56154\\OneDrive - Elevance Health\\Desktop\\workshop_material\\Total training material\\Transformers_data\\Transformers_data\\train.fr\",\n",
    "          mode='r',\n",
    "          encoding='utf-8') as f:\n",
    "    eurotrain_fr = f.read()\n",
    "    \n",
    "with open(r\"C:\\Users\\AL56154\\OneDrive - Elevance Health\\Desktop\\workshop_material\\Total training material\\Transformers_data\\Transformers_data\\dev.en\",\n",
    "          mode='r',\n",
    "          encoding='utf-8') as f:\n",
    "    eurodev_en = f.read()\n",
    "    \n",
    "with open(r\"C:\\Users\\AL56154\\OneDrive - Elevance Health\\Desktop\\workshop_material\\Total training material\\Transformers_data\\Transformers_data\\dev.fr\",\n",
    "          mode='r',\n",
    "          encoding='utf-8') as f:\n",
    "    eurodev_fr = f.read()\n",
    "with open(r\"C:\\Users\\AL56154\\OneDrive - Elevance Health\\Desktop\\workshop_material\\Total training material\\Transformers_data\\Transformers_data\\test.en\",\n",
    "          mode='r',\n",
    "          encoding='utf-8') as f:\n",
    "    eurotest_en = f.read()\n",
    "    \n",
    "with open(r\"C:\\Users\\AL56154\\OneDrive - Elevance Health\\Desktop\\workshop_material\\Total training material\\Transformers_data\\Transformers_data\\test.fr\",\n",
    "          mode='r',\n",
    "          encoding='utf-8') as f:\n",
    "    eurotest_fr = f.read()  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "62ff87e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Vous savez, un des plaisirs intenses du voyage et un des délices de la recherche ethnographique est la possibilité de vivre parmi ceux qui n'ont pas oublié les anciennes coutumes, qui ressentent encore leur passé souffler dans le vent, qui le touchent dans les pierres polies par la pluie, le dégustent dans les feuilles amères des plantes.\\nLe fait de savoir que les Jaguar shaman voyagent toujours au-delà de la voie lactée, ou que les mythes des anciens Inuit résonnent encore de sens, ou bien que dans l'Himalaya, les Bouddhistes continuent à rechercher le souffle du Dharma, c'est se rappeler de la révélation essentielle de l'anthropologie, et cela veut dire que le monde dans lequel nous vivons n'existe pas dans un sens absolu, mais est uniquement un exemple de réalité, la conséquence d'un ensemble spécifique de choix adaptés établis par notre lignée avec succès, il y a plusieurs générations.\\nBien sûr, nous partageons tous les mêmes impératifs d'adaptation.\\nNous sommes tous nés. Nous appo\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eurodev_fr[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db8b7e8",
   "metadata": {
    "id": "xZ9gZSpBEdqY"
   },
   "source": [
    "## Preprocessing the corpus\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247ade30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEANING THE ENGLISH TEXT\n",
    "corpus_en = eurotrain_en\n",
    "corpus_en = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\",\" \", corpus_en)\n",
    "corpus_en = corpus_en.split('\\n')\n",
    "\n",
    "\n",
    "#CLEANING THE ENGLISH TEXT\n",
    "corpus_en_test = eurotest_en\n",
    "corpus_en_test = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\",\" \", corpus_en_test)\n",
    "corpus_en_test = corpus_en_test.split('\\n')\n",
    "\n",
    "#CLEANING THE ENGLISH TEXT\n",
    "corpus_fr_test = eurotest_fr\n",
    "corpus_fr_test = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\",\" \", corpus_fr_test)\n",
    "corpus_fr_test = corpus_fr_test.split('\\n')\n",
    "\n",
    "#CLEANING THE FRENCH TEXT\n",
    "corpus_fr = eurotrain_fr\n",
    "corpus_fr = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\",\" \", corpus_fr)\n",
    "corpus_fr = corpus_fr.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "56596108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"David Gallo: This is Bill Lange. I'm Dave Gallo.\",\n",
       " \"And we're going to tell you some stories from the sea here in video.\",\n",
       " \"We've got some of the most incredible video of Titanic that's ever been seen, and we're not going to show you any of it.\",\n",
       " \"The truth of the matter is that the Titanic -- even though it's breaking all sorts of box office records -- it's not the most exciting story from the sea.\",\n",
       " 'And the problem, I think, is that we take the ocean for granted.',\n",
       " 'When you think about it, the oceans are 75 percent of the planet.',\n",
       " 'Most of the planet is ocean water.',\n",
       " 'The average depth is about two miles.',\n",
       " \"Part of the problem, I think, is we stand at the beach, or we see images like this of the ocean, and you look out at this great big blue expanse, and it's shimmering and it's moving and there's waves and there's surf and there's tides, but you have no idea for what lies in there.\",\n",
       " 'And in the oceans, there are the longest mountain ranges on the planet.']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_en[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bfa05e",
   "metadata": {
    "id": "R_kPuNqqSDdB"
   },
   "source": [
    "### Building Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8da02fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer for English\n",
    "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    corpus_en, target_vocab_size=2**13)### Building vocab using training set only\n",
    "\n",
    "# Tokenizer for French\n",
    "tokenizer_fr = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    corpus_fr, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb56d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE_EN = tokenizer_en.vocab_size + 2 # = 8190\n",
    "VOCAB_SIZE_FR = tokenizer_fr.vocab_size + 2 # = 8171"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e495f4d",
   "metadata": {
    "id": "HmW_BTl_F4gh"
   },
   "source": [
    "## Encoding train and test sets each set with the respective language tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab0145a",
   "metadata": {
    "id": "wMJw8gueFUuA"
   },
   "source": [
    "## Adding __\\<SOS\\>__ and __\\<EOS\\>__ tags\n",
    "- Adding the Start of Sentence and End of Sentence tags to the corpus is to indicate the transformer the beginning and end of sentence for better sequential data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0714caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[VOCAB_SIZE_EN-2] + tokenizer_en.encode(sentence) + [VOCAB_SIZE_EN-1] \n",
    "          for sentence in corpus_en]\n",
    "\n",
    "outputs = [[VOCAB_SIZE_FR-2] + tokenizer_fr.encode(sentence) + [VOCAB_SIZE_FR-1]\n",
    "           for sentence in corpus_fr]\n",
    "\n",
    "inputs_test = [[VOCAB_SIZE_EN-2] + tokenizer_en.encode(sentence) + [VOCAB_SIZE_EN-1]\n",
    "          for sentence in corpus_en_test]\n",
    "\n",
    "outputs_test = [[VOCAB_SIZE_FR-2] + tokenizer_fr.encode(sentence) + [VOCAB_SIZE_FR-1]\n",
    "           for sentence in corpus_fr_test]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e55ccb",
   "metadata": {
    "id": "HL-kWJatGBR4"
   },
   "source": [
    "# Removing very long sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d4246b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing very long sentencesMAX_LENGTH = 40\n",
    "# Use enumerate to capture indexes\n",
    "idx_to_remove = [count for count, sent in enumerate(inputs)\n",
    "                 if len(sent) > MAX_LENGTH]\n",
    "\n",
    "# Remove long sentences by index\n",
    "for idx in reversed(idx_to_remove):\n",
    "    del inputs[idx]\n",
    "    del outputs[idx]\n",
    "\n",
    "# Rinse and repeate!    \n",
    "idx_to_remove = [count for count, sent in enumerate(outputs)\n",
    "                 if len(sent) > MAX_LENGTH]\n",
    "\n",
    "for idx in reversed(idx_to_remove):\n",
    "    del inputs[idx]\n",
    "    del outputs[idx]\n",
    "    \n",
    "idx_to_remove = [count for count, sent in enumerate(inputs_test)\n",
    "                 if len(sent) > MAX_LENGTH]\n",
    "\n",
    "# Remove long sentences by index\n",
    "for idx in reversed(idx_to_remove):\n",
    "    del inputs_test[idx]\n",
    "    del outputs_test[idx]\n",
    "\n",
    "# Rinse and repeate!    \n",
    "idx_to_remove = [count for count, sent in enumerate(outputs_test)\n",
    "                 if len(sent) > MAX_LENGTH]\n",
    "\n",
    "for idx in reversed(idx_to_remove):\n",
    "    del inputs_test[idx]\n",
    "    del outputs_test[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4878cdff",
   "metadata": {
    "id": "NmcPrymHGHLM"
   },
   "source": [
    "# Padding the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9349675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                       value=0,\n",
    "                                              # Padding the sentences         padding='post',\n",
    "                                                       maxlen=MAX_LENGTH)\n",
    "\n",
    "outputs = tf.keras.preprocessing.sequence.pad_sequences(outputs,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=MAX_LENGTH)\n",
    "inputs_test = tf.keras.preprocessing.sequence.pad_sequences(inputs_test,\n",
    "                                                       value=0,\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=MAX_LENGTH)\n",
    "\n",
    "outputs_test = tf.keras.preprocessing.sequence.pad_sequences(outputs_test,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9eed32",
   "metadata": {
    "id": "lMZ6JucFGOJr"
   },
   "source": [
    "# Creation of train and test Datasets (tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb860d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000# Creation of Datasets (tf.data.Dataset)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((inputs_test, outputs_test))\n",
    "\n",
    "dataset_test = dataset_test.cache()\n",
    "dataset_test = dataset_test.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "dataset_test = dataset_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c6b300",
   "metadata": {
    "id": "FvQHNdMWGUBh"
   },
   "source": [
    "# Postional Encoding\n",
    "> Q. Why do transformers use positional encodings in addition to word\n",
    "embeddings? Explain how positional encodings are incorporated into the\n",
    "transformer architecture. <br><br>\n",
    "> A. The order of the words in a sentence is important to understand it correctly. The transformer model receives the words all at once, and not sequentially. So positional encodings (PE) are responsible for capturing this order information. PEs are concatated with the word embeddings for the transformer to not only understand the meaning of each word, but also their order in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4920323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "    \n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        '''# Postional Encoding\n",
    "> Q. Why do transformers use positional encodings in addition to word\n",
    "embeddings? Explain how positional encodings are incorporated into the\n",
    "transformer architecture. <br><br>\n",
    "> A. The order of the words in a sentence is important to understand it correctly. The transformer model receives the words all at once, and not sequentially. So positional encodings (PE) are responsible for capturing this order information. PEs are concatated with the word embeddings for the transformer to not only understand the meaning of each word, but also their order in the sequence.\n",
    "        pos     - (seq_length, 1) matrix\n",
    "        i       - (1, d_model) matrix\n",
    "        d_model - the size of the embedding vectors\n",
    "        '''\n",
    "        angles = 1 / np.power(10000., (2*(i//2)) / np.float32(d_model))\n",
    "        return pos * angles\n",
    "\n",
    "    def call(self, inputs):\n",
    "        ''' \n",
    "        inputs - the word embeddings - (batch_size, seq_length, d_model)\n",
    "        '''\n",
    "        seq_length = inputs.shape.as_list()[-2]\n",
    "        d_model = inputs.shape.as_list()[-1]\n",
    "        \n",
    "        angles = self.get_angles(np.arange(seq_length)[:, np.newaxis],\n",
    "                                 np.arange(d_model)[np.newaxis, :],\n",
    "                                 d_model)\n",
    "        \n",
    "        # Interleve the results of sine and cosine funtions along the embedding vectors\n",
    "        angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
    "        angles[:, 1::2] = np.cos(angles[:, 1::2])\n",
    "        \n",
    "        # Add dimension for batch_size\n",
    "        pos_encoding = angles[np.newaxis, ...]\n",
    "        return inputs + tf.cast(pos_encoding, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e4eca",
   "metadata": {
    "id": "UqFc305aHnHF"
   },
   "source": [
    "## Calculating attention and attention matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cb503e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Calculate attention\n",
    "### Calculating attention and attention matrix## Multi Head Attention\n",
    "\n",
    "> Q. What is the purpose of self-attention, and how does it facilitate capturing\n",
    "dependencies in sequences? <br> <br>\n",
    "> A. As you read a book, your brain pays more \"attention\" to certain words when trying to understand the meaning of a sentence. Instead of focusing on pronouns (such as he/she) or articles (such as they/them), you focus on adverbs, adjectives, proper nouns, etc., This is the idea behind self attention in a Transformer model. It \"weighs\" the importance of words in a sequence when processing each word. This way, the model can capture dependencies between words regardless of their distance from each other in the sequence.\n",
    "\n",
    "\n",
    "def scaled_dot_product_attention(queries, keys, values, mask):\n",
    "    '''\n",
    "    Takes three vectors and mask\n",
    "    Returns the attention and attention weights\n",
    "    '''    \n",
    "    # The steps describe above under 'Calculate the Attention' \n",
    "    # Step 1 \n",
    "    product = tf.matmul(queries, keys, transpose_b=True)\n",
    "    \n",
    "    # Step 2\n",
    "    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
    "    scaled_product = product / tf.math.sqrt(keys_dim)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scaled_product += (mask * -1e9)\n",
    "    \n",
    "    # step 4\n",
    "    attention_weights =tf.nn.softmax(scaled_product, axis=-1)\n",
    "    \n",
    "    # Step 5\n",
    "    attention = tf.matmul(attention_weights, values)\n",
    "    \n",
    "    return attention, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ae708e",
   "metadata": {
    "id": "1KNQg0e_HzLc"
   },
   "source": [
    "## Multi Head Attention\n",
    "\n",
    "> Q. What is the purpose of self-attention, and how does it facilitate capturing\n",
    "dependencies in sequences? <br> <br>\n",
    "> A. As you read a book, your brain pays more \"attention\" to certain words when trying to understand the meaning of a sentence. Instead of focusing on pronouns (such as he/she) or articles (such as they/them), you focus on adverbs, adjectives, proper nouns, etc., This is the idea behind self attention in a Transformer model. It \"weighs\" the importance of words in a sequence when processing each word. This way, the model can capture dependencies between words regardless of their distance from each other in the sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62a0b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(layers.Layer):\n",
    "    \n",
    "    # nb_proj is the number of heads\n",
    "    def __init__(self, nb_proj):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.nb_proj = nb_proj\n",
    "        \n",
    "    def build(self, input_shape): \n",
    "        self.d_model = input_shape[-1]\n",
    "        assert self.d_model % self.nb_proj == 0\n",
    "        \n",
    "        # Calculate the head dimensions.\n",
    "        self.d_proj = self.d_model // self.nb_proj\n",
    "        \n",
    "        # These layers contain the weights for the linear transformations\n",
    "        self.query_lin = layers.Dense(units=self.d_model)\n",
    "        self.key_lin = layers.Dense(units=self.d_model)\n",
    "        self.value_lin = layers.Dense(units=self.d_model)\n",
    "        \n",
    "        # Used to transform after concatenating the weighted value vectors\n",
    "        self.final_lin = layers.Dense(units=self.d_model)\n",
    "    \n",
    "    # This method splits the query, key, and value vectors by the number of heads\n",
    "    def split_proj(self, inputs, batch_size): # inputs: (batch_size, seq_length, d_model)\n",
    "        shape = (batch_size,\n",
    "                 -1,\n",
    "                 self.nb_proj,\n",
    "                 self.d_proj)\n",
    "        \n",
    "        # Reshape the tensor to account for the multiple heads and reduced vector dimension\n",
    "        splited_inputs = tf.reshape(inputs, shape=shape) # (batch_size, seq_length, nb_proj, d_proj)\n",
    "        \n",
    "        # Reconfigure the axeses.\n",
    "        return tf.transpose(splited_inputs, perm=[0, 2, 1, 3]) # (batch_size, nb_proj, seq_length, d_proj)\n",
    "    \n",
    "    def call(self, queries, keys, values, mask):\n",
    "        '''\n",
    "        If this is the first attention layer of the encoder, then all vector inputs are the same vector.\n",
    "        For later layers, this is the output of the previous layer.\n",
    "        For the decoder, keys and values are the output of the encoder. \n",
    "            The queries is the inferred words up to this time step.        \n",
    "        '''\n",
    "        batch_size = tf.shape(queries)[0]\n",
    "        \n",
    "        # Initialize the weight matrices\n",
    "        queries = self.query_lin(queries)\n",
    "        keys = self.key_lin(keys)\n",
    "        values = self.value_lin(values)\n",
    "        \n",
    "        # Split the vectors by number of heads\n",
    "        queries = self.split_proj(queries, batch_size)\n",
    "        keys = self.split_proj(keys, batch_size)\n",
    "        values = self.split_proj(values, batch_size)\n",
    "        \n",
    "        # Get attention and weights\n",
    "        attention, attention_weights = scaled_dot_product_attention(queries,\n",
    "                                                                    keys,\n",
    "                                                                    values,\n",
    "                                                                    mask)\n",
    "        # Flip dims 1 and 2       \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        # Concat all the attention vectors\n",
    "        concat_attention = tf.reshape(attention,\n",
    "                                      shape=(batch_size, -1, self.d_model))\n",
    "        \n",
    "        # Transform the concated vectors to reshape back to (batch_size, seq_length, d_model)\n",
    "        outputs = self.final_lin(concat_attention)\n",
    "        \n",
    "        return outputs, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2a30f",
   "metadata": {
    "id": "c7zcjOVPJIq4"
   },
   "source": [
    "## Building the encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbb828a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(layers.Layer):## Building the encoder layer\n",
    "    \n",
    "    def __init__(self, FFN_units, nb_proj, dropout_rate):        \n",
    "    \n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.FFN_units = FFN_units\n",
    "        self.nb_proj = nb_proj\n",
    "        self.dropout_rate = dropout_rate\n",
    "    \n",
    "    # This is a tensorflow layers method. Automatically called by __call__\n",
    "    # to automatically build the layers.\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.d_model = input_shape[-1]\n",
    "    \n",
    "        # Multi-head attention\n",
    "        self.multi_head_attention = MultiHeadAttention(self.nb_proj)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        # Point wise feed forward\n",
    "        self.dense_1 = layers.Dense(units=self.FFN_units, activation=\"relu\")\n",
    "        self.dense_2 = layers.Dense(units=self.d_model)\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def call(self, inputs, mask, training):\n",
    "        '''\n",
    "        inputs   -> Input tensor of shape (batch_size, seq_length, d_model)\n",
    "        mask     -> Padding mask to ignore padding zeros as data\n",
    "        training -> Boolean - If 1, then use dropout, else not\n",
    "        '''\n",
    "        # Attention sub-layer\n",
    "        # Retain only the attention. Don't need to return weights in this layer.\n",
    "        attention, _ = self.multi_head_attention(inputs,\n",
    "                                                 inputs,\n",
    "                                                 inputs,\n",
    "                                                 mask)\n",
    "        attention = self.dropout_1(attention, training=training)\n",
    "        attention = self.norm_1(attention + inputs)\n",
    "        \n",
    "        # Point-Wise Feed Forward sub-layer\n",
    "        outputs = self.dense_1(attention)\n",
    "        outputs = self.dense_2(outputs)\n",
    "        outputs = self.dropout_2(outputs, training=training)\n",
    "        outputs = self.norm_2(outputs + attention)\n",
    "        \n",
    "        # Returns tensor of shape (batch_size, seq_length, d_model)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea643c2",
   "metadata": {
    "id": "RrOsnQQtJMb2"
   },
   "source": [
    "# The Encoder stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e84b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    '''\n",
    "    nb_layers    -> Number of encoder layers\n",
    "    FFN_units    -> Number of nodes in the FFN\n",
    "    nb_proj      -> Number of attention heads\n",
    "    dropout_rate -> Droput rate# The Encoder stack\n",
    "    vocab_size   -> The size of the vocabulary\n",
    "    d_model      -> Size of embedding vectors\n",
    "    name         -> Name of the layer\n",
    "    '''    \n",
    "    def __init__(self,\n",
    "                 nb_layers,\n",
    "                 FFN_units,\n",
    "                 nb_proj,\n",
    "                 dropout_rate,\n",
    "                 vocab_size,\n",
    "                 d_model,\n",
    "                 name=\"encoder\"):\n",
    "        super(Encoder, self).__init__(name=name)\n",
    "        \n",
    "        # Number of encoder layers\n",
    "        self.nb_layers = nb_layers\n",
    "        # Embedding dimension\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Initialize embedding, positional encoding, droppout, and encoding layers\n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        self.enc_layers = [EncoderLayer(FFN_units,\n",
    "                                        nb_proj,\n",
    "                                        dropout_rate) \n",
    "                           for _ in range(nb_layers)]\n",
    "    \n",
    "    def call(self, inputs, mask, training):\n",
    "        '''\n",
    "        inputs   -> Tokenized input of shape (batch_size, seq_length)\n",
    "        mask     -> Attention mask\n",
    "        training -> Boolean\n",
    "        '''\n",
    "        outputs = self.embedding(inputs)\n",
    "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        outputs = self.pos_encoding(outputs)\n",
    "        outputs = self.dropout(outputs, training)\n",
    "        \n",
    "        # Forward pass\n",
    "        for i in range(self.nb_layers):\n",
    "            outputs = self.enc_layers[i](outputs, mask, training)\n",
    "\n",
    "        # Returns tensor of shape (batch_size, seq_length, d_model)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3126e5d",
   "metadata": {
    "id": "cdR-lsJ7JPDd"
   },
   "source": [
    "## Buidling the Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15ceafb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(layers.Layer):\n",
    "    '''## Buidling the Decoder Layer\n",
    "    FFN-units    -> # of nodes for the point wise feed forward layer\n",
    "    nb_proj      -> # of heads\n",
    "    dropout_rate -> The dropout rate for the layers\n",
    "    '''\n",
    "    def __init__(self, FFN_units, nb_proj, dropout_rate):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.FFN_units = FFN_units\n",
    "        self.nb_proj = nb_proj\n",
    "        self.dropout_rate = dropout_rate\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.d_model = input_shape[-1]\n",
    "        \n",
    "        # Masked Multi-head attention layer\n",
    "        self.multi_head_attention_1 = MultiHeadAttention(self.nb_proj)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        # encoder-decoder Multi-head attention\n",
    "        self.multi_head_attention_2 = MultiHeadAttention(self.nb_proj)\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        # Feed foward\n",
    "        self.dense_1 = layers.Dense(units=self.FFN_units,\n",
    "                                    activation=\"relu\")\n",
    "        self.dense_2 = layers.Dense(units=self.d_model)\n",
    "        self.dropout_3 = layers.Dropout(rate=self.dropout_rate)\n",
    "        self.norm_3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
    "        '''\n",
    "        input       -> Decoder output\n",
    "        enc_outputs -> Encoder output\n",
    "        mask_1      -> Look-ahead mask\n",
    "        mask_2      -> Padding mask\n",
    "        training    -> Boolean for dropout\n",
    "        '''\n",
    "        # Masked Multi-head attention layer \n",
    "        # Return attention, attention weights\n",
    "        attention, attn_wt_1 = self.multi_head_attention_1(inputs,\n",
    "                                                           inputs,\n",
    "                                                           inputs,\n",
    "                                                           mask_1)\n",
    "        attention = self.dropout_1(attention, training)\n",
    "        attention = self.norm_1(attention + inputs)\n",
    "        \n",
    "        # Encoder-Decoder Multi-head attention layer \n",
    "        # Return attention, attention weights\n",
    "        attention_2, attn_wt_2 = self.multi_head_attention_2(attention,\n",
    "                                                             enc_outputs,\n",
    "                                                             enc_outputs,\n",
    "                                                             mask_2)\n",
    "        attention_2 = self.dropout_2(attention_2, training)\n",
    "        attention_2 = self.norm_2(attention_2 + attention)\n",
    "        \n",
    "        # FNN\n",
    "        outputs = self.dense_1(attention_2)\n",
    "        outputs = self.dense_2(outputs)\n",
    "        outputs = self.dropout_3(outputs, training)\n",
    "        outputs = self.norm_3(outputs + attention_2)\n",
    "        \n",
    "        # Return attention vector, attention weights for each attention layer\n",
    "        return outputs, attn_wt_1, attn_wt_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7732c0eb",
   "metadata": {
    "id": "dZhvRymNJR7Y"
   },
   "source": [
    "## The Decoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f329fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    '''## The Decoder layer\n",
    "    nb_layers    -> Number of encoder layers\n",
    "    FFN_units    -> Number of nodes in the FFN\n",
    "    nb_proj      -> Number of attention heads\n",
    "    dropout_rate -> Droput rate\n",
    "    vocab_size   -> The size of the vocabulary\n",
    "    d_model      -> Size of embedding vectors\n",
    "    name         -> Name of the layer\n",
    "    '''    \n",
    "    def __init__(self,\n",
    "                 nb_layers,\n",
    "                 FFN_units,\n",
    "                 nb_proj,\n",
    "                 dropout_rate,\n",
    "                 vocab_size,\n",
    "                 d_model,\n",
    "                 name=\"decoder\"):\n",
    "        super(Decoder, self).__init__(name=name)\n",
    "        self.d_model = d_model\n",
    "        self.nb_layers = nb_layers\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        \n",
    "        # Initialize the decoder layers.\n",
    "        self.dec_layers = [DecoderLayer(FFN_units,\n",
    "                                        nb_proj,\n",
    "                                        dropout_rate) \n",
    "                           for i in range(nb_layers)]\n",
    "    \n",
    "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
    "        '''\n",
    "        input       -> Decoder output\n",
    "        enc_outputs -> Encoder output\n",
    "        mask_1      -> Look-ahead mask\n",
    "        mask_2      -> Padding mask\n",
    "        training    -> Boolean for dropout\n",
    "        '''\n",
    "        outputs = self.embedding(inputs)\n",
    "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        outputs = self.pos_encoding(outputs)\n",
    "        outputs = self.dropout(outputs, training)\n",
    "        \n",
    "        # Iterate over the decoder layers.\n",
    "        for i in range(self.nb_layers):\n",
    "            \n",
    "            attention_weights = {}\n",
    "\n",
    "            # Block 1 and block2 are the attention weights from each attention head of the layer\n",
    "            outputs, block1, block2 = self.dec_layers[i](outputs, enc_outputs, mask_1, mask_2, training)\n",
    "            \n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "\n",
    "        return outputs, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97351adb",
   "metadata": {
    "id": "yc0ANSc0JYHQ"
   },
   "source": [
    "## Creating the Transformer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3fef726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):## Creating the Transformer Class\n",
    "    '''\n",
    "    vocab_size_enc -> Vocabulary size of the encoder input\n",
    "    vocab_size_dec -> Vocabulary size of the decoder input\n",
    "    d_model        -> Embedding size\n",
    "    nb_layers      -> Number of encoder and decoder layers\n",
    "    FFN_units      -> Noumber of nodes in the FNNs \n",
    "    nb_proj        -> Number of heads\n",
    "    dropout_rate   -> Dropout rate throught model\n",
    "    name           -> Layer name\n",
    "    '''    \n",
    "    def __init__(self,\n",
    "                 vocab_size_enc,\n",
    "                 vocab_size_dec,\n",
    "                 d_model,\n",
    "                 nb_layers,\n",
    "                 FFN_units,\n",
    "                 nb_proj,\n",
    "                 dropout_rate,\n",
    "                 name=\"transformer\"):\n",
    "        super(Transformer, self).__init__(name=name)\n",
    "        \n",
    "        self.encoder = Encoder(nb_layers,\n",
    "                               FFN_units,\n",
    "                               nb_proj,\n",
    "                               dropout_rate,\n",
    "                               vocab_size_enc,\n",
    "                               d_model)\n",
    "        \n",
    "        self.decoder = Decoder(nb_layers,\n",
    "                               FFN_units,\n",
    "                               nb_proj,\n",
    "                               dropout_rate,\n",
    "                               vocab_size_dec,\n",
    "                               d_model)\n",
    "        \n",
    "        self.last_linear = layers.Dense(units=vocab_size_dec, name=\"lin_ouput\")\n",
    "    \n",
    "    def create_padding_mask(self, seq):\n",
    "        \n",
    "        mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "        return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    def create_look_ahead_mask(self, seq):\n",
    "        \n",
    "        seq_len = tf.shape(seq)[1]\n",
    "        look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "        return look_ahead_mask\n",
    "    \n",
    "    def call(self, enc_inputs, dec_inputs, training):\n",
    "        \n",
    "        enc_mask = self.create_padding_mask(enc_inputs)\n",
    "        dec_mask_1 = tf.maximum(\n",
    "            self.create_padding_mask(dec_inputs),\n",
    "            self.create_look_ahead_mask(dec_inputs)\n",
    "        )\n",
    "        dec_mask_2 = self.create_padding_mask(enc_inputs)\n",
    "        \n",
    "        # encoder output\n",
    "        enc_outputs = self.encoder(enc_inputs, enc_mask, training)\n",
    "        \n",
    "        # dec_outputs, attention_weights\n",
    "        dec_outputs, attention_weights = self.decoder(dec_inputs,\n",
    "                                                      enc_outputs,\n",
    "                                                      dec_mask_1,\n",
    "                                                      dec_mask_2,\n",
    "                                                      training)\n",
    "        \n",
    "        # This is the prediction\n",
    "        outputs = self.last_linear(dec_outputs)\n",
    "        \n",
    "        # Return prediction (batch_size, tar_seq_len, target_vocab_size), and attention_weight matrix\n",
    "        return outputs, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87142e0c",
   "metadata": {
    "id": "MEJtk_NWJiAX"
   },
   "source": [
    "## Defining Hyperparameters before training\n",
    "\n",
    "- The comments next to the values are the orginal values used in the paper __Attention is all you need__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d72623dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "## Defining Hyperparameters before training\n",
    "\n",
    "- The comments next to the values are the orginal values used in the paper __Attention is all you need__\n",
    "# Hyper-parameters\n",
    "D_MODEL = 128 # 512\n",
    "NB_LAYERS = 4 # 6\n",
    "FFN_UNITS = 512 # 2048\n",
    "NB_PROJ = 8 # 8\n",
    "DROPOUT_RATE = 0.1 # 0.1\n",
    "\n",
    "# Initialize the transformer\n",
    "transformer = Transformer(vocab_size_enc=VOCAB_SIZE_EN,\n",
    "                          vocab_size_dec=VOCAB_SIZE_FR,\n",
    "                          d_model=D_MODEL,\n",
    "                          nb_layers=NB_LAYERS,\n",
    "                          FFN_units=FFN_UNITS,\n",
    "                          nb_proj=NB_PROJ,\n",
    "                          dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8a0a64",
   "metadata": {
    "id": "yh17vAC-Jy_D"
   },
   "source": [
    "## Defining LOSS function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "892417ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                      ## Defining LOSS function      reduction=\"none\")\n",
    "\n",
    "def loss_function(target, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(target, 0))\n",
    "    loss_ = loss_object(target, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581fce32",
   "metadata": {
    "id": "yiLtsDqfJ2Pw"
   },
   "source": [
    "## Defining a custom learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ae1296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):## Defining a custom learning rate\n",
    "    \n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "        \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "leaning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "# Use the Atom Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(leaning_rate,\n",
    "                                     beta_1=0.9,\n",
    "                                     beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a023e0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(leaning_rate(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "# plt.savefig(ROOT + '/data/lr.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6373e0b9",
   "metadata": {
    "id": "AKwIsnpLJ7i_"
   },
   "source": [
    "## Begin the Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62cfee6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training Loss: 0.3179 Training Accuracy: 0.4377 \n",
      "Epoch: 2 Training Loss: 0.3042 Training Accuracy: 0.4412 \n",
      "Epoch: 3 Training Loss: 0.2939 Training Accuracy: 0.4435 \n",
      "Epoch: 4 Training Loss: 0.2844 Training Accuracy: 0.4460 \n",
      "Epoch: 5 Training Loss: 0.2728 Training Accuracy: 0.4492 \n",
      "Epoch: 6 Training Loss: 0.2641 Training Accuracy: 0.4510 \n",
      "Epoch: 7 Training Loss: 0.2548 Training Accuracy: 0.4536 \n",
      "Epoch: 8 Training Loss: 0.2459 Training Accuracy: 0.4558 \n",
      "Epoch: 9 Training Loss: 0.2398 Training Accuracy: 0.4576 \n",
      "Epoch: 10 Training Loss: 0.2328 Training Accuracy: 0.4591 \n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "train_loss_values=[]\n",
    "test_loss_values=[]\n",
    "\n",
    "train_acc_values=[]\n",
    "test_acc_values=[]## Begin the Training!\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "#     print(\"Start of epoch {}\".format(epoch+1))\n",
    "    start = time.time()\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    for (batch, (enc_inputs, targets)) in enumerate(dataset):\n",
    "        \n",
    "        # Include the start token which shifts sequence to the right\n",
    "        dec_inputs = targets[:, :-1]\n",
    "        \n",
    "        # Target without the start token. The end token is included to know when the \n",
    "        # model reaches the end of the sequence\n",
    "        dec_outputs_real = targets[:, 1:]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions, _ = transformer(enc_inputs, dec_inputs, True)\n",
    "            loss = loss_function(dec_outputs_real, predictions)\n",
    "        \n",
    "        # Calculate and apply the gradients\n",
    "        gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "        \n",
    "        train_loss(loss)\n",
    "        train_accuracy(dec_outputs_real, predictions)\n",
    "        \n",
    "#         if batch % 50 == 0:\n",
    "    print(\"Epoch: {} Training Loss: {:.4f} Training Accuracy: {:.4f} \".format(\n",
    "                epoch+1, train_loss.result(), train_accuracy.result()))\n",
    "    \n",
    "    train_loss_values.append(train_loss.result())\n",
    "    train_acc_values.append(train_accuracy.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d403656",
   "metadata": {},
   "source": [
    "# Defining Evaluation Fucntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0bca215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    '''\n",
    "    Takes the input sentence.\n",
    "    '''\n",
    "    inp_sentence = [VOCAB_SIZE_EN-2] + tokenizer_en.encode(inp_sentence) + [VOCAB_SIZE_EN-1]\n",
    "    \n",
    "    # Expand dims to account for batch_size\n",
    "    enc_input = tf.expand_dims(inp_sentence, axis=0)\n",
    "    \n",
    "    # Start with the s-o-s\n",
    "    output = tf.expand_dims([VOCAB_SIZE_FR-2], axis=0)\n",
    "    \n",
    "    for _ in range(MAX_LENGTH):\n",
    "        predictions, attention_weights = transformer(enc_input, output, False)\n",
    "        \n",
    "        prediction = predictions[:, -1:, :]\n",
    "#         print(predictions.shape)\n",
    "        # Get highest probability\n",
    "        predicted_id = tf.cast(tf.argmax(prediction, axis=-1), tf.int32)\n",
    "        \n",
    "        # If e-o-s return\n",
    "        if predicted_id == VOCAB_SIZE_FR-1:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "        \n",
    "        # Concat last prediction to decoder input\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "        \n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f7d0fa",
   "metadata": {},
   "source": [
    "# Defining a function to perform Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "189ff09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "    #output, attention_weights\n",
    "    output, attention_weights = evaluate(sentence) #.numpy()\n",
    "#     print(f'wts shape: {attention_weights.keys()}')\n",
    "    output = output.numpy()\n",
    "    \n",
    "    predicted_sentence = tokenizer_fr.decode(\n",
    "        [i for i in output if i < VOCAB_SIZE_FR-2]\n",
    "    )\n",
    "    \n",
    "    print(\"Input_English_Sentence: {}\".format(sentence))\n",
    "    print(\"Predicted translation into French: {}\".format(predicted_sentence))\n",
    "#     return predicted_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb90833",
   "metadata": {},
   "source": [
    "# Testing the translation from English to French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e5bb1bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input_English_Sentence: my country is great\n",
      "Predicted translation into French: Mon pays est super.\n"
     ]
    }
   ],
   "source": [
    "translate(\"my country is great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "97535ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input_English_Sentence: When I was in my 20s, I saw my very first psychotherapy client.\n",
      "Predicted translation into French: Quand j'étais dans mon 20, j'ai vu mon premier domaine très rifié les autres,\n"
     ]
    }
   ],
   "source": [
    "translate(\"When I was in my 20s, I saw my very first psychotherapy client.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ba414",
   "metadata": {},
   "source": [
    "## Sample BLEU score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ee25908b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BLEU Score for the above translation is: 0.18669510440057904\n"
     ]
    }
   ],
   "source": [
    "##Bleu Score CAlculation\n",
    "\n",
    "target= \"Quand j'avais la vingtaine, j'ai vu mes tout premiers clients comme psychothérapeute.\"\n",
    "prediction = \"Quand j'étais dans mon 20, j'ai vu mon premier domaine très rifié les autres\"\n",
    "\n",
    "target_seq = tokenizer_fr.encode(target)\n",
    "target_tokens = [tokenizer_fr.decode([i]) for i in target_seq]\n",
    "\n",
    "pred_seq = tokenizer_fr.encode(prediction)\n",
    "preds = [tokenizer_fr.decode([i]) for i in pred_seq]\n",
    "\n",
    "print(f\"The BLEU Score for the above translation is: {sentence_bleu([target_tokens],preds)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e58ff",
   "metadata": {},
   "source": [
    "# Ploting Train loss and Train Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70634211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    " \n",
    "# Plot Training Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_values, label='Training Loss')\n",
    "# plt.plot(val_loss_values, label='Validation Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc_values, label='Training Accuracy')\n",
    "# plt.plot(val_loss_values, label='Validation Loss')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320ff9ae",
   "metadata": {},
   "source": [
    "## Conclusion: The training loss is decreasing and training accuracy is increasing with the increase in the number of epochs. The BLEU score for a sample translated sentence is presented above. The model can perform better if trained for more epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
